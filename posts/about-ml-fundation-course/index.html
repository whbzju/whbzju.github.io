<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>机器学习基石课程总结 | Wujia Blog</title><meta name=viewport content="width=device-width,minimum-scale=1"><meta name=description content="课程一开始，提了四个topic，what every machine learning user should know
* when can ml learn * why can ml learn * how can ml learn * how can ml learn better When can ml learn 首先，机器学习针对的场景，通过A对D和H学习一个g，用来描述最终的目标f，而这个事情无法简单的用规则搞定。其次，澄清各类细分ml场景的定义：
* 监督式 * 非监督式 * 增强学习 * 推进系统 * Activity学习，通过asking来学习 * Streaming why can ml learn * shatter的概念 * break point的概念 * generation问题 * VC维的概念 how can ml learn 讲了一些基本的linear方法，比如logistic regression，顺便提了下nonlinear的问题，通过transform将nonlinear映射到linear可分的空间，有点类似核函数，需要进一步确认。
how can ml learn better * overfiting * regularition，这块数学不错。从拉格朗日的constraint说起，到L1和L2的直观意义。 * cv * 三个重要的Principle。Occam's Razor， Sample Bias， Data Snooping."><meta name=generator content="Hugo 0.104.3"><meta name=robots content="noindex, nofollow"><link rel=stylesheet href=/ananke/css/main.min.css><meta property="og:title" content="机器学习基石课程总结"><meta property="og:description" content="课程一开始，提了四个topic，what every machine learning user should know
* when can ml learn * why can ml learn * how can ml learn * how can ml learn better When can ml learn 首先，机器学习针对的场景，通过A对D和H学习一个g，用来描述最终的目标f，而这个事情无法简单的用规则搞定。其次，澄清各类细分ml场景的定义：
* 监督式 * 非监督式 * 增强学习 * 推进系统 * Activity学习，通过asking来学习 * Streaming why can ml learn * shatter的概念 * break point的概念 * generation问题 * VC维的概念 how can ml learn 讲了一些基本的linear方法，比如logistic regression，顺便提了下nonlinear的问题，通过transform将nonlinear映射到linear可分的空间，有点类似核函数，需要进一步确认。
how can ml learn better * overfiting * regularition，这块数学不错。从拉格朗日的constraint说起，到L1和L2的直观意义。 * cv * 三个重要的Principle。Occam's Razor， Sample Bias， Data Snooping."><meta property="og:type" content="article"><meta property="og:url" content="https://whbzju.github.io/posts/about-ml-fundation-course/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2014-12-28T11:07:00+08:00"><meta property="article:modified_time" content="2014-12-28T11:07:00+08:00"><meta itemprop=name content="机器学习基石课程总结"><meta itemprop=description content="课程一开始，提了四个topic，what every machine learning user should know
* when can ml learn * why can ml learn * how can ml learn * how can ml learn better When can ml learn 首先，机器学习针对的场景，通过A对D和H学习一个g，用来描述最终的目标f，而这个事情无法简单的用规则搞定。其次，澄清各类细分ml场景的定义：
* 监督式 * 非监督式 * 增强学习 * 推进系统 * Activity学习，通过asking来学习 * Streaming why can ml learn * shatter的概念 * break point的概念 * generation问题 * VC维的概念 how can ml learn 讲了一些基本的linear方法，比如logistic regression，顺便提了下nonlinear的问题，通过transform将nonlinear映射到linear可分的空间，有点类似核函数，需要进一步确认。
how can ml learn better * overfiting * regularition，这块数学不错。从拉格朗日的constraint说起，到L1和L2的直观意义。 * cv * 三个重要的Principle。Occam's Razor， Sample Bias， Data Snooping."><meta itemprop=datePublished content="2014-12-28T11:07:00+08:00"><meta itemprop=dateModified content="2014-12-28T11:07:00+08:00"><meta itemprop=wordCount content="90"><meta itemprop=keywords content="machine,learning,"><meta name=twitter:card content="summary"><meta name=twitter:title content="机器学习基石课程总结"><meta name=twitter:description content="课程一开始，提了四个topic，what every machine learning user should know
* when can ml learn * why can ml learn * how can ml learn * how can ml learn better When can ml learn 首先，机器学习针对的场景，通过A对D和H学习一个g，用来描述最终的目标f，而这个事情无法简单的用规则搞定。其次，澄清各类细分ml场景的定义：
* 监督式 * 非监督式 * 增强学习 * 推进系统 * Activity学习，通过asking来学习 * Streaming why can ml learn * shatter的概念 * break point的概念 * generation问题 * VC维的概念 how can ml learn 讲了一些基本的linear方法，比如logistic regression，顺便提了下nonlinear的问题，通过transform将nonlinear映射到linear可分的空间，有点类似核函数，需要进一步确认。
how can ml learn better * overfiting * regularition，这块数学不错。从拉格朗日的constraint说起，到L1和L2的直观意义。 * cv * 三个重要的Principle。Occam's Razor， Sample Bias， Data Snooping."></head><body class="ma0 avenir bg-near-white"><header><div class=bg-black><nav class="pv3 ph3 ph4-ns" role=navigation><div class="flex-l justify-between items-center center"><a href=/ class="f3 fw2 hover-white no-underline white-90 dib">Wujia Blog</a><div class="flex-l items-center"><div class=ananke-socials></div></div></div></nav></div></header><main class=pb7 role=main><article class="flex-l flex-wrap justify-between mw8 center ph3"><header class="mt4 w-100"><aside class="instapaper_ignoref b helvetica tracked">POSTS</aside><div id=sharing class="mt3 ananke-socials"></div><h1 class="f1 athelas mt3 mb1">机器学习基石课程总结</h1><time class="f6 mv4 dib tracked" datetime=2014-12-28T11:07:00+08:00>December 28, 2014</time></header><div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>课程一开始，提了四个topic，what every machine learning user should know</p><pre><code>* when can ml learn
* why can ml learn
* how can ml learn
* how can ml learn better
</code></pre><h2 id=when-can-ml-learn>When can ml learn</h2><p>首先，机器学习针对的场景，通过<em>A</em>对<em>D</em>和<em>H</em>学习一个g，用来描述最终的目标f，而这个事情无法简单的用规则搞定。其次，澄清各类细分ml场景的定义：</p><pre><code>* 监督式
* 非监督式
* 增强学习
* 推进系统
* Activity学习，通过asking来学习
* Streaming
</code></pre><h2 id=why-can-ml-learn>why can ml learn</h2><pre><code>* shatter的概念
* break point的概念
* generation问题
* VC维的概念
</code></pre><h2 id=how-can-ml-learn>how can ml learn</h2><p>讲了一些基本的linear方法，比如logistic regression，顺便提了下nonlinear的问题，通过transform将nonlinear映射到linear可分的空间，有点类似核函数，需要进一步确认。</p><h2 id=how-can-ml-learn-better>how can ml learn better</h2><pre><code>* overfiting
* regularition，这块数学不错。从拉格朗日的constraint说起，到L1和L2的直观意义。
* cv
* 三个重要的Principle。Occam's Razor， Sample Bias， Data Snooping.
</code></pre><h2 id=我对这门课的收获>我对这门课的收获</h2><pre><code>* 霍夫曼定理
* VC维的理解，线性相关
* 略微有点啰嗦，为了避免数学，导致描述的复杂度上升好几个级别
</code></pre><p>总体来讲，对工程人员帮助不是特别大，但有利于加深概念的理解。</p><ul class=pa0><li class="list di"><a href=/tags/machine/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">machine</a></li><li class="list di"><a href=/tags/learning/ class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">learning</a></li></ul><div class="mt6 instapaper_ignoref"></div></div><aside class="w-30-l mt6-l"><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links"><p class="f5 b mb3">What's in this posts</p><nav id=TableOfContents><ul><li><a href=#when-can-ml-learn>When can ml learn</a></li><li><a href=#why-can-ml-learn>why can ml learn</a></li><li><a href=#how-can-ml-learn>how can ml learn</a></li><li><a href=#how-can-ml-learn-better>how can ml learn better</a></li><li><a href=#我对这门课的收获>我对这门课的收获</a></li></ul></nav></div><div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links"><p class="f5 b mb3">Related</p><ul class="pa0 list"><li class=mb2><a href=/posts/ipython-notebook-bring-to-me/>ipython notebook对机器学习工程师的价值</a></li><li class=mb2><a href=/posts/ml-distance-measure/>聚类算法中常见的距离计算方法</a></li><li class=mb2><a href=/posts/r-language-conference/>记第七届R语言大会</a></li></ul></div></aside></article></main><footer class="bg-black bottom-0 w-100 pa3" role=contentinfo><div class="flex justify-between"><a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://whbzju.github.io/>&copy; Wujia Blog 2022</a><div><div class=ananke-socials></div></div></div></footer></body></html>